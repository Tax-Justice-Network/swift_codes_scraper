{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format and Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook formatting\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVER_PATH = \"/Users/danielcoll/Library/Drivers/chromedriver\"\n",
    "ROOT_URL = \"https://swift-codes.org/all-country/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "import json\n",
    "\n",
    "# Load selenium components\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Constants and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_first_level_links(driver):\n",
    "    driver.get(ROOT_URL)\n",
    "    # Retrieve list of first level bic country links\n",
    "    country_list = driver.find_element(By.CLASS_NAME, \"country-list\")\n",
    "    lis = country_list.find_elements(By.TAG_NAME, \"li\")\n",
    "    links = []\n",
    "    for li in lis:\n",
    "        a = li.find_element(By.TAG_NAME, \"a\")\n",
    "        link = a.get_attribute(\"href\")\n",
    "        links.append(link)\n",
    "    return links\n",
    "\n",
    "\n",
    "def scrap_second_level_links(driver, first_level_links):\n",
    "    second_level_links = []\n",
    "    for first_level_link in first_level_links:\n",
    "        # Access to first level link and wait until the page is fully loaded\n",
    "        try:\n",
    "            driver.get(first_level_link)\n",
    "            element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, \"myDynamicElement\"))\n",
    "            )\n",
    "        except:\n",
    "            print(\"Something went wrong loading the page\")\n",
    "        # Retrieve list of second level bic country links\n",
    "        post_titles = driver.find_elements(By.CLASS_NAME, \"post-title.entry-title\")\n",
    "        for post_title in post_titles:\n",
    "            a = post_title.find_elements(By.TAG_NAME, \"a\")\n",
    "            for elem in a:\n",
    "                second_level_link = elem.get_attribute(\"href\")\n",
    "                second_level_links.append(second_level_link)\n",
    "\n",
    "    return second_level_links\n",
    "\n",
    "\n",
    "def scrap_bic_dataset_from_html_table(driver, links):\n",
    "    for index, link in zip(list(range(len(links))), links):\n",
    "        # Access to first level link and wait until the page is fully loaded\n",
    "        print(index, link)\n",
    "        try:\n",
    "            try:\n",
    "                driver.get(link)\n",
    "                element = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.ID, \"myDynamicElement\"))\n",
    "                )\n",
    "            except:\n",
    "                print(\"Something went wrong loading the page\")\n",
    "\n",
    "            # Retrieve bic datasets\n",
    "            tables = driver.find_elements(By.TAG_NAME, \"table\")\n",
    "            for i, table in enumerate(tables):\n",
    "                if i == 0:\n",
    "                    df = pd.read_html(table.get_attribute(\"outerHTML\"), header=0)[0]\n",
    "                    df_0_column_names = df.columns.tolist()\n",
    "                    print(df_0_column_names)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    df_n = pd.read_html(table.get_attribute(\"outerHTML\"))[0]\n",
    "                    print(df_n)\n",
    "                    df_n.columns = df_0_column_names\n",
    "                    df = df.append(df_n)\n",
    "            df.to_csv(f\"../data/intermediary/{index}.csv\", index=False)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish chrome driver and go to report site URL\n",
    "driver = webdriver.Chrome(DRIVER_PATH)\n",
    "# Extract first level links\n",
    "first_level_links = scrap_first_level_links(driver)\n",
    "# Extract second level links\n",
    "second_level_links = scrap_second_level_links(driver, first_level_links)\n",
    "# Extract data from link endpoints\n",
    "scrap_bic_dataset_from_html_table(driver, second_level_links)\n",
    "# Close driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HSBCDZA1XXX', 'PRBAARBABAH', 'PRBAARBADIV', 'PRBAARBALPT', 'PRBAARBAMP1']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve bic numbers from csv files\n",
    "bic_numbers = []\n",
    "for i in list(range(370)):\n",
    "    try:\n",
    "        df = pd.read_csv(f\"../data/intermediary/{i}.csv\")\n",
    "        columns = df.columns.to_list()\n",
    "        for column in columns:\n",
    "            bic_keywords = [\"BIC\", \"bic\", \"SWIFT\", \"swift\"]\n",
    "            if any(substring in column for substring in bic_keywords):\n",
    "                # print(df[column].loc[df[column].notnull()].tolist())\n",
    "                bic_numbers += df[column].loc[df[column].notnull()].tolist()\n",
    "    except:\n",
    "        pass\n",
    "bic_numbers[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bic number list to json file\n",
    "json_object = json.dumps(bic_numbers)\n",
    "with open(\"../data/final/bic_numbers.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('web_scraping')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2cc90161b87ec4837004ac9c329f9f1ed5618723289f0ce1c9b58541f3fd007"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
